{"allContent":{"docusaurus-plugin-content-docs":{"default":{"loadedVersions":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/ai-book/","tagsPath":"/ai-book/tags","editUrl":"https://github.com/tanzeelnaveed8/ai-book/tree/main/docs","isLast":true,"routePriority":-1,"sidebarFilePath":"C:\\Users\\DELL LATITUDE\\Desktop\\tanzeel\\ai-book\\sidebars.js","contentPath":"C:\\Users\\DELL LATITUDE\\Desktop\\tanzeel\\ai-book\\docs","docs":[{"id":"advanced-locomotion/advanced-bipedal-locomotion","title":"Advanced Bipedal Locomotion","description":"Introduction","source":"@site/docs/advanced-locomotion/advanced-bipedal-locomotion.md","sourceDirName":"advanced-locomotion","slug":"/advanced-locomotion/advanced-bipedal-locomotion","permalink":"/ai-book/advanced-locomotion/advanced-bipedal-locomotion","draft":false,"unlisted":false,"editUrl":"https://github.com/tanzeelnaveed8/ai-book/tree/main/docs/advanced-locomotion/advanced-bipedal-locomotion.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"advanced-bipedal-locomotion","title":"Advanced Bipedal Locomotion","sidebar_position":1}},{"id":"capstone/overview","title":"Capstone Project Overview","description":"The capstone project is the culmination of all the skills learned throughout this course. Your team will design, simulate, and deploy a complete Vision-Language-Action (VLA) pipeline on a simulated robot. The final goal is to have a robot that can respond to a natural language voice command to identify, navigate to, and interact with an object in a simulated environment.","source":"@site/docs/capstone/overview.md","sourceDirName":"capstone","slug":"/capstone/overview","permalink":"/ai-book/capstone/overview","draft":false,"unlisted":false,"editUrl":"https://github.com/tanzeelnaveed8/ai-book/tree/main/docs/capstone/overview.md","tags":[],"version":"current","frontMatter":{"id":"overview","title":"Capstone Project Overview","sidebar_label":"Overview"},"sidebar":"tutorialSidebar","previous":{"title":"Hardware Setup","permalink":"/ai-book/hardware/setup"},"next":{"title":"Glossary","permalink":"/ai-book/glossary"}},{"id":"ethical-implications/ethical-social-implications","title":"Ethical and Social Implications of Humanoid Robotics","description":"Introduction","source":"@site/docs/ethical-implications/ethical-social-implications.md","sourceDirName":"ethical-implications","slug":"/ethical-implications/ethical-social-implications","permalink":"/ai-book/ethical-implications/ethical-social-implications","draft":false,"unlisted":false,"editUrl":"https://github.com/tanzeelnaveed8/ai-book/tree/main/docs/ethical-implications/ethical-social-implications.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"ethical-social-implications","title":"Ethical and Social Implications of Humanoid Robotics","sidebar_position":1}},{"id":"future-trends/future-trends-physical-ai","title":"Future Trends in Physical AI","description":"Introduction","source":"@site/docs/future-trends/future-trends-physical-ai.md","sourceDirName":"future-trends","slug":"/future-trends/future-trends-physical-ai","permalink":"/ai-book/future-trends/future-trends-physical-ai","draft":false,"unlisted":false,"editUrl":"https://github.com/tanzeelnaveed8/ai-book/tree/main/docs/future-trends/future-trends-physical-ai.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"future-trends-physical-ai","title":"Future Trends in Physical AI","sidebar_position":1}},{"id":"glossary","title":"Glossary","description":"A B C D E F G H I J K L M N O P Q R S T U V W X Y Z","source":"@site/docs/glossary.md","sourceDirName":".","slug":"/glossary","permalink":"/ai-book/glossary","draft":false,"unlisted":false,"editUrl":"https://github.com/tanzeelnaveed8/ai-book/tree/main/docs/glossary.md","tags":[],"version":"current","frontMatter":{"id":"glossary","title":"Glossary","sidebar_label":"Glossary"},"sidebar":"tutorialSidebar","previous":{"title":"Overview","permalink":"/ai-book/capstone/overview"},"next":{"title":"References","permalink":"/ai-book/references"}},{"id":"hardware/setup","title":"Hardware & Infrastructure Setup","description":"This course is technically demanding. It sits at the intersection of three heavy computational loads: Physics Simulation, Visual Perception, and Generative AI. Standard laptops, including MacBooks or non-RTX Windows machines, will not work for local development.","source":"@site/docs/hardware/setup.md","sourceDirName":"hardware","slug":"/hardware/setup","permalink":"/ai-book/hardware/setup","draft":false,"unlisted":false,"editUrl":"https://github.com/tanzeelnaveed8/ai-book/tree/main/docs/hardware/setup.md","tags":[],"version":"current","frontMatter":{"id":"setup","title":"Hardware & Infrastructure Setup","sidebar_label":"Hardware Setup"},"sidebar":"tutorialSidebar","previous":{"title":"Weeks 1-13","permalink":"/ai-book/weekly-map/weeks-1-13"},"next":{"title":"Overview","permalink":"/ai-book/capstone/overview"}},{"id":"human-robot-collaboration/human-robot-collaboration","title":"Human-Robot Collaboration","description":"Introduction","source":"@site/docs/human-robot-collaboration/human-robot-collaboration.md","sourceDirName":"human-robot-collaboration","slug":"/human-robot-collaboration/","permalink":"/ai-book/human-robot-collaboration/","draft":false,"unlisted":false,"editUrl":"https://github.com/tanzeelnaveed8/ai-book/tree/main/docs/human-robot-collaboration/human-robot-collaboration.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"human-robot-collaboration","title":"Human-Robot Collaboration","sidebar_position":1}},{"id":"introduction/chapter1","title":"Introduction to Physical AI","description":"Concept Explanation","source":"@site/docs/introduction/chapter1.md","sourceDirName":"introduction","slug":"/introduction/chapter1","permalink":"/ai-book/introduction/chapter1","draft":false,"unlisted":false,"editUrl":"https://github.com/tanzeelnaveed8/ai-book/tree/main/docs/introduction/chapter1.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"chapter1","title":"Introduction to Physical AI","sidebar_position":1},"sidebar":"tutorialSidebar","next":{"title":"Modules","permalink":"/ai-book/modules"}},{"id":"module1/chapter2","title":"Advanced Control Systems for Humanoid Robotics","description":"Introduction to Advanced Control","source":"@site/docs/module1/chapter2.md","sourceDirName":"module1","slug":"/module1/chapter2","permalink":"/ai-book/module1/chapter2","draft":false,"unlisted":false,"editUrl":"https://github.com/tanzeelnaveed8/ai-book/tree/main/docs/module1/chapter2.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"chapter2","title":"Advanced Control Systems for Humanoid Robotics","sidebar_position":1}},{"id":"modules/01-ros-2","title":"Module 1: The Robotic Nervous System (ROS 2)","description":"This module introduces the Robot Operating System (ROS 2), the middleware that acts as the nervous system for our humanoid robots. You will learn how to structure robot software, manage data flow, and bridge high-level Python code with low-level robot controllers.","source":"@site/docs/modules/01-ros-2.md","sourceDirName":"modules","slug":"/modules/01-ros-2","permalink":"/ai-book/modules/01-ros-2","draft":false,"unlisted":false,"editUrl":"https://github.com/tanzeelnaveed8/ai-book/tree/main/docs/modules/01-ros-2.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"01-ros-2","title":"Module 1: The Robotic Nervous System (ROS 2)","sidebar_label":"ROS 2 Nervous System"},"sidebar":"tutorialSidebar","previous":{"title":"Modules","permalink":"/ai-book/modules"},"next":{"title":"Digital Twin Simulation","permalink":"/ai-book/modules/02-digital-twin"}},{"id":"modules/02-digital-twin","title":"Module 2: The Digital Twin (Gazebo & Unity)","description":"In this module, you will learn how to create and use a \"Digital Twin\"—a high-fidelity simulation of a real-world robot and its environment. This is a critical skill in modern robotics, as it allows for rapid prototyping, testing, and AI model training in a safe, cost-effective, and repeatable virtual world before deploying to physical hardware.","source":"@site/docs/modules/02-digital-twin.md","sourceDirName":"modules","slug":"/modules/02-digital-twin","permalink":"/ai-book/modules/02-digital-twin","draft":false,"unlisted":false,"editUrl":"https://github.com/tanzeelnaveed8/ai-book/tree/main/docs/modules/02-digital-twin.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"02-digital-twin","title":"Module 2: The Digital Twin (Gazebo & Unity)","sidebar_label":"Digital Twin Simulation"},"sidebar":"tutorialSidebar","previous":{"title":"ROS 2 Nervous System","permalink":"/ai-book/modules/01-ros-2"},"next":{"title":"NVIDIA Isaac","permalink":"/ai-book/modules/03-nvidia-isaac"}},{"id":"modules/03-nvidia-isaac","title":"Module 3: The AI-Robot Brain (NVIDIA Isaac™)","description":"This module dives into the NVIDIA Isaac platform, a powerful toolkit for developing AI-powered robots. We will focus on using Isaac Sim for photorealistic simulation and synthetic data generation, and Isaac ROS for hardware-accelerated perception and navigation tasks. This is where we give our robot a \"brain\" capable of advanced understanding of its environment.","source":"@site/docs/modules/03-nvidia-isaac.md","sourceDirName":"modules","slug":"/modules/03-nvidia-isaac","permalink":"/ai-book/modules/03-nvidia-isaac","draft":false,"unlisted":false,"editUrl":"https://github.com/tanzeelnaveed8/ai-book/tree/main/docs/modules/03-nvidia-isaac.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"03-nvidia-isaac","title":"Module 3: The AI-Robot Brain (NVIDIA Isaac™)","sidebar_label":"NVIDIA Isaac"},"sidebar":"tutorialSidebar","previous":{"title":"Digital Twin Simulation","permalink":"/ai-book/modules/02-digital-twin"},"next":{"title":"Vision-Language-Action","permalink":"/ai-book/modules/04-vla-systems"}},{"id":"modules/04-vla-systems","title":"Module 4: Vision-Language-Action (VLA)","description":"This module explores the exciting convergence of Large Language Models (LLMs), computer vision, and robotics. We will learn how to build Vision-Language-Action (VLA) systems that allow a robot to understand natural language commands, perceive the world through vision, and execute complex, multi-step tasks. This is how we give the robot a \"cognitive\" understanding of its mission.","source":"@site/docs/modules/04-vla-systems.md","sourceDirName":"modules","slug":"/modules/04-vla-systems","permalink":"/ai-book/modules/04-vla-systems","draft":false,"unlisted":false,"editUrl":"https://github.com/tanzeelnaveed8/ai-book/tree/main/docs/modules/04-vla-systems.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"04-vla-systems","title":"Module 4: Vision-Language-Action (VLA)","sidebar_label":"Vision-Language-Action"},"sidebar":"tutorialSidebar","previous":{"title":"NVIDIA Isaac","permalink":"/ai-book/modules/03-nvidia-isaac"},"next":{"title":"Bipedal Locomotion","permalink":"/ai-book/modules/05-bipedal-locomotion"}},{"id":"modules/05-bipedal-locomotion","title":"Module 5: Bipedal Locomotion","description":"This module tackles one of the grand challenges of humanoid robotics: achieving stable, efficient, and dynamic bipedal locomotion. We will explore the fundamental principles of kinematics and dynamics, investigate classic and modern gait generation algorithms, and delve into the control strategies required to keep a two-legged robot balanced while walking, running, and navigating the world.","source":"@site/docs/modules/05-bipedal-locomotion.md","sourceDirName":"modules","slug":"/modules/05-bipedal-locomotion","permalink":"/ai-book/modules/05-bipedal-locomotion","draft":false,"unlisted":false,"editUrl":"https://github.com/tanzeelnaveed8/ai-book/tree/main/docs/modules/05-bipedal-locomotion.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"id":"05-bipedal-locomotion","title":"Module 5: Bipedal Locomotion","sidebar_label":"Bipedal Locomotion"},"sidebar":"tutorialSidebar","previous":{"title":"Vision-Language-Action","permalink":"/ai-book/modules/04-vla-systems"},"next":{"title":"Human-Robot Interaction","permalink":"/ai-book/modules/06-human-robot-interaction"}},{"id":"modules/06-human-robot-interaction","title":"Module 6: Human-Robot Interaction (HRI)","description":"This module transitions from the mechanics of robot motion to the subtleties of robot interaction. We will explore how to design humanoid robots that can work with, understand, and be understood by humans. This involves cognitive robotics, interaction design, and the emerging field of \"Emotion AI\" to make robots more intuitive and socially aware partners.","source":"@site/docs/modules/06-human-robot-interaction.md","sourceDirName":"modules","slug":"/modules/06-human-robot-interaction","permalink":"/ai-book/modules/06-human-robot-interaction","draft":false,"unlisted":false,"editUrl":"https://github.com/tanzeelnaveed8/ai-book/tree/main/docs/modules/06-human-robot-interaction.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"id":"06-human-robot-interaction","title":"Module 6: Human-Robot Interaction (HRI)","sidebar_label":"Human-Robot Interaction"},"sidebar":"tutorialSidebar","previous":{"title":"Bipedal Locomotion","permalink":"/ai-book/modules/05-bipedal-locomotion"},"next":{"title":"Ethics & Society","permalink":"/ai-book/modules/07-ethics-and-society"}},{"id":"modules/07-ethics-and-society","title":"Module 7: Ethics & Society","description":"As we build increasingly capable humanoid robots, we have an obligation to consider their impact on society. This module steps back from the technical details to critically examine the ethical challenges and societal implications of deploying autonomous systems in the human world. We will discuss safety, algorithmic bias, the future of work, and our responsibility as engineers and designers.","source":"@site/docs/modules/07-ethics-and-society.md","sourceDirName":"modules","slug":"/modules/07-ethics-and-society","permalink":"/ai-book/modules/07-ethics-and-society","draft":false,"unlisted":false,"editUrl":"https://github.com/tanzeelnaveed8/ai-book/tree/main/docs/modules/07-ethics-and-society.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"id":"07-ethics-and-society","title":"Module 7: Ethics & Society","sidebar_label":"Ethics & Society"},"sidebar":"tutorialSidebar","previous":{"title":"Human-Robot Interaction","permalink":"/ai-book/modules/06-human-robot-interaction"},"next":{"title":"Future Trends","permalink":"/ai-book/modules/08-future-trends"}},{"id":"modules/08-future-trends","title":"Module 8: Future Trends","description":"In this final module, we look to the horizon. Having mastered the current state of the art, we will explore the speculative and cutting-edge research that is shaping the future of physical AI. From direct brain-robot interfaces to robots that learn on their own and the regulatory landscapes that will govern them, we will discuss what's next for humanoid robotics.","source":"@site/docs/modules/08-future-trends.md","sourceDirName":"modules","slug":"/modules/08-future-trends","permalink":"/ai-book/modules/08-future-trends","draft":false,"unlisted":false,"editUrl":"https://github.com/tanzeelnaveed8/ai-book/tree/main/docs/modules/08-future-trends.md","tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"id":"08-future-trends","title":"Module 8: Future Trends","sidebar_label":"Future Trends"},"sidebar":"tutorialSidebar","previous":{"title":"Ethics & Society","permalink":"/ai-book/modules/07-ethics-and-society"},"next":{"title":"Weeks 1-13","permalink":"/ai-book/weekly-map/weeks-1-13"}},{"id":"references","title":"References","description":"This page will house a curated list of key academic papers, textbooks, and online resources referenced throughout the course modules.","source":"@site/docs/references.md","sourceDirName":".","slug":"/references","permalink":"/ai-book/references","draft":false,"unlisted":false,"editUrl":"https://github.com/tanzeelnaveed8/ai-book/tree/main/docs/references.md","tags":[],"version":"current","frontMatter":{"id":"references","title":"References","sidebar_label":"References"},"sidebar":"tutorialSidebar","previous":{"title":"Glossary","permalink":"/ai-book/glossary"}},{"id":"weekly-map/weeks-1-13","title":"Weekly Learning Map","description":"This document outlines the structured, week-by-week curriculum for the Physical AI & Humanoid Robotics course. Each section details the lessons, key learning objectives, and expected assessments.","source":"@site/docs/weekly-map/weeks-1-13.md","sourceDirName":"weekly-map","slug":"/weekly-map/weeks-1-13","permalink":"/ai-book/weekly-map/weeks-1-13","draft":false,"unlisted":false,"editUrl":"https://github.com/tanzeelnaveed8/ai-book/tree/main/docs/weekly-map/weeks-1-13.md","tags":[],"version":"current","frontMatter":{"id":"weeks-1-13","title":"Weekly Learning Map","sidebar_label":"Weeks 1-13"},"sidebar":"tutorialSidebar","previous":{"title":"Future Trends","permalink":"/ai-book/modules/08-future-trends"},"next":{"title":"Hardware Setup","permalink":"/ai-book/hardware/setup"}}],"drafts":[],"sidebars":{"tutorialSidebar":[{"type":"category","label":"Course Introduction","items":[{"type":"doc","id":"introduction/chapter1"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Modules","link":{"type":"generated-index","title":"Course Modules","description":"Deep dive into the core concepts of Physical AI and Humanoid Robotics.","slug":"/modules","permalink":"/ai-book/modules"},"items":[{"type":"doc","id":"modules/01-ros-2"},{"type":"doc","id":"modules/02-digital-twin"},{"type":"doc","id":"modules/03-nvidia-isaac"},{"type":"doc","id":"modules/04-vla-systems"},{"type":"doc","id":"modules/05-bipedal-locomotion"},{"type":"doc","id":"modules/06-human-robot-interaction"},{"type":"doc","id":"modules/07-ethics-and-society"},{"type":"doc","id":"modules/08-future-trends"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Weekly Learning Map","items":[{"type":"doc","id":"weekly-map/weeks-1-13"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Hardware & Infrastructure","items":[{"type":"doc","id":"hardware/setup"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Capstone Project","items":[{"type":"doc","id":"capstone/overview"}],"collapsed":true,"collapsible":true},{"type":"doc","id":"glossary"},{"type":"doc","id":"references"}]}}]}},"docusaurus-plugin-content-pages":{"default":[{"type":"jsx","permalink":"/ai-book/","source":"@site/src/pages/index.tsx"},{"type":"jsx","permalink":"/ai-book/LayoutWrapper","source":"@site/src/pages/LayoutWrapper.js"}]},"docusaurus-plugin-debug":{},"docusaurus-plugin-svgr":{},"docusaurus-theme-classic":{},"docusaurus-bootstrap-plugin":{},"docusaurus-mdx-fallback-plugin":{}}}